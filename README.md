# 第四屆《機器學習百日馬拉松》
### 機器學習概論
*  DAY1: 資料分析與評估資料
*  DAY2: 機器學習概論
*  DAY3: 機器學習-流程與步驟
*  DAY4: EDA-讀取資料與分析流程
### 資料清理數據前處理
*  DAY5: 如何新建一個DataFrame? 如何讀取其他資料(非CSV資料)?
*  DAY6: EDA-欄位的資料類型介紹與處理
*  DAY7: 特徵類型
*  DAY8: EDA資料分佈
*  DAY9: EDA-Outlier及處理
* DAY10: 數值型特徵-去除離群值
* DAY11: 常用的數值取代: 中位數與分位數連續數值標準化
* DAY12: 數值型特徵-補缺失值與標準化
* DAY13: DataFrame OperationData Frame Merge/常用的DataFrame操作
* DAY14: 程式實作EDA-Correlation/相關係數簡介
* DAY15: EDA from Correlation
* DAY16: EDA-不同數值範圍間的特徵如何檢視/繪圖與樣式Kernel Density Estimation(KDE)
* DAY17: EDA-把連續型變數離散化
* DAY18: 程式實作-把連續型變數離散化
* DAY19: Subplots
* DAY20: Heatmap & Grid-plot
* DAY21: 模型初體驗-Logistic Regression
### 資料科學特徵工程技術
* DAY22: 特徵工程簡介
* DAY23: 數值型特徵-去除偏態
* DAY24: 類別型特徵-基礎處理
* DAY25: 類別型特徵-均值編碼
* DAY26: 類別型特徵-其他進階處理
* DAY27: 時間型特徵
* DAY28: 特徵組合-數值與數值組合
* DAY29: 特徵組合-類別與數值組合
* DAY30: 特徵選擇
* DAY31: 特徵評估
* DAY32: 分類型特徵優化-葉編碼
### 機器學習基礎模型建立
* DAY33: 機器如何學習?
* DAY34: 訓練/測試集切分的概念
* DAY35: Regression v.s Classification
* DAY36: 評估指標選定/Evaluation Metrics
* DAY37: Regression Model介紹-線性回歸/羅吉斯回歸
* DAY38: Regression Model-線性/羅吉斯回歸模型程式碼撰寫
* DAY39: Regression Model介紹-LASSO回歸/Ridge回歸
* DAY40: Regression Model-LASSO/Ridge回歸程式碼撰寫
* DAY41: Tree Based Model-決策樹(Desion Tree)模型介紹
* DAY42: Tree Based Model-決策樹程式碼撰寫
* DAY43: Tree Based Model-隨機森林(Random Forest)介紹
* DAY44: Tree Based Model-隨機森林程式碼撰寫
* DAY45: Tree Based Model-梯度提升機(Gradient Boosting Machine)介紹
* DAY46: Tree Based Model-梯度提升機程式碼撰寫
### 機器學習調整參數
* DAY47: 超參數調整與優化
* DAY48: Kaggle競賽平台介紹
* DAY49: 集成方法:混合泛化(Blending)
* DAY50: 集成方法:堆疊泛化(Stacking)
### 非監督式機器學習
* DAY54: Clustering1 - 非監督式機器學習簡介
* DAY55: Clustering2 - 聚類算法
* DAY56: K-mean觀察: 使用輪廓分析
* DAY57: Clustering3 - 階層分群算法
* DAY58: 階層分群法觀察: 使用2D樣板資料集
* DAY59: Dimension Reduction1 - 降維方法-主成份分析
* DAY60: PCA觀察:使用手寫辨識資料集
* DAY61: Dimension Reduction2 - 降維方法-T-SNE
* DAY62: T-SNE觀察: 分群與流形還原
### 深度學習理論與實作
* DAY63: 神經網路介紹
* DAY64: 深度學習體驗:模型調整與學習曲線
* DAY65: 深度學習體驗:啟動函數與正規化

